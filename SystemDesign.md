### **Why the need for so many tiers**

> 1. **Single responsibility principle** simply means giving only one responsibility to a component and letting it execute it perfectly, be it saving data, running the application logic or ensuring the delivery of the messages throughout the system. This approach gives us a lot of flexibility and makes management easier. 
> 2. **Separation of concerns** kind of means the same thing, be concerned about your work only and stop worrying about the rest of the stuff. Keeping the components separate makes them reusable. 



### What is REST
> 1. **REST** stands for **Representational State Transfer**. Itâ€™s a software architectural style for implementing web services. Web services implemented using the REST architectural style are known as the **RESTful Web services**.
>
> 1. RESTä¸º**è¡¨ç°å±‚çŠ¶æ€è½¬æ¢**ï¼Œæ˜¯ä¸€ç§æ„å»ºç½‘ç»œæœåŠ¡çš„è½¯ä»¶æ¶æ„é£æ ¼ï¼Œç¬¦åˆè¿™ç§é£æ ¼çš„ç½‘ç»œæœåŠ¡å°±å«**RESTful**ç½‘ç»œæœåŠ¡
>
>    
- ### Steps of solve System Design Programs
> 1. **Requirements clarification**s. æ˜ç¡®éœ€æ±‚
> 2. **Back-of-the-envelope estimation**.It is always a good idea to estimate the scale of the system weâ€™re going to design. ç²—ç•¥è¯„ä¼°
> 3. **System interface definition**.Define what APIs are expected from the system. å®šä¹‰ç³»ç»Ÿæ¥å£
> 4. **Defining data model**.The ata model will clarify how data will flow between different system components. Later, it will guide for data partitioning and management.(e.g. storage, transportation, encryption)å®šä¹‰æ•°æ®æ¨¡å‹
> 4. **High-level design**.Design the core components of our system.We should identify enough components that are needed to solve the actual problem from end to end.
> 4. **Detailed design**.There is no single answer,the only important thing is to consider ***Tradeoffs  between different options while keeping system constraints in mind***.ç»†èŠ‚è®¾è®¡
> 4. **Identifying and resolving bottlenecks**.æ‰¾åˆ°å¹¶è§£å†³ç³»ç»Ÿç“¶é¢ˆ
> > -  Is there any single point of failure in our system.
> > -  How are we monitoring the performance of our service.




### Key Characteristics of Distributed Systems
> 1. **Scalability**
> > - *Horizontal*: add more servers. scale by adding more servers into pool of resources.  æ°´å¹³å¢åŠ æœºå™¨
> > - *Vertical*: add more resources to the same server.  scale by adding more power (CPU, RAM, Storage, etc.) to an existing server.  æé«˜å•æœºæ€§èƒ½
> 2. **Reliability**.keeps delivering its services even when one or several of its software or hardware components fail
> 2. **Availability**.is the time a system remains operational to perform its required function in a specific period.
> 2. **Efficiency**.
> > - *response time (or latency) that denotes the delay to obtain the first item*
> > - *the throughput (or bandwidth) which denotes the number of items delivered in a given time unit (e.g., a second)*
> 5. **Manageability**.how easy it is to operate and maintain



### Cache

___
- ### Keep the cache coherent with the source of truthç¼“å­˜ä¸åº“ä¸€è‡´æ€§
> 1. **Write-through cache:** Under this scheme, data is written into the cache and the corresponding database simultaneously. ç¼“å­˜ä¸åº“***åŒæ—¶å†™***
>	+ we will have complete data consistency between the cache and the storage.
>	+ this scheme has the disadvantage of higher latency for write operations.
> 2. **Write-around cache:** This technique is similar to write-through cache, but data is written directly to permanent storage, bypassing the cache.åªå†™åº“***ä¸å†™ç¼“å­˜***
> 	+ This can reduce the cache being flooded with write operations that will not subsequently be re-read
> 	+ disadvantage that a read request for recently written data will create a â€œcache missâ€ and must be read from slower back-end storage and experience higher latency.
> 3. **Write-back cache:** Data is written to cache alone, and completion is immediately confirmed to the client.The write to the permanent storage is done after specified intervals or under certain conditions.åªå†™ç¼“å­˜***ä¸å†™åº“***
> 	+ low-latency and high-throughput for write-intensive applications.
> 	+  risk of data loss  because the only copy of the written data is in the cache.
- ### Cache eviction policiesç¼“å­˜æ·˜æ±°ç­–ç•¥
> 1. **First In First Out (FIFO)**: The cache evicts the first block accessed first without any regard to how often or how many times it was accessed before.
> 2. **Last In First Out (LIFO)**: The cache evicts the block accessed most recently first without any regard to how often or how many times it was accessed before.
> 3. **Least Recently Used (LRU)**: Discards the least recently used items first.
> 4. **Most Recently Used (MRU)**: Discards, in contrast to LRU, the most recently used items first.
> 5. **Least Frequently Used (LFU)**: Counts how often an item is needed. Those that are used least often are discarded first.
> 6. **Random Replacement (RR)**: Randomly selects a candidate item and discards it to make space when necessary.





### Socket Error

> - ***man errno***
> -  **EAGAIN**    Resource temporarily unavailable (may be the same value as EWOULDBLOCK) (this error can be ignore e.g. ZeroMQ).
> -  **EWOULDBLOCK**     Operation would block (may be same value as EAGAIN) (POSIX.1-2001).



### ZeroMQ
> - A high-performance asynchronous messaging library,It provides a message queue.
> - ZeroMQ supports *common messaging patterns* (**pub/sub, request/reply, client/server** and others) over a variety of transports (TCP, in-process, inter-process, multicast, WebSocket and more), making inter-process messaging as simple as inter-thread messaging. 
>	- The inter-process transport passes messages between local processes using a system-dependent IPC mechanism. 
>	- The in-process transport passes messages via memory directly between threads sharing a single Ã˜MQ *context*.
> - A ZeroMQ message is a discrete unit of data passed between applications or components of the same application.


### Redis
> - åºå·å‘ç”Ÿå™¨ INCR key
> - æ»‘åŠ¨çª—å£ APIé™æµï¼ˆä½¿ç”¨Sorted Seté…åˆzaddï¼Œzremrankbyscoreï¼Œzcard)


#### Redis Persistence
1. `AOF(Append Only File) `é€šè¿‡ä¿å­˜Redisçš„**å†™å‘½ä»¤**æ¥ä¿å­˜æ•°æ®åº“çŠ¶æ€ã€‚å…·ä½“é€šè¿‡`å‘½ä»¤è¿½åŠ `ã€`æ–‡ä»¶å†™å…¥åŒæ­¥`ä¸‰ä¸ªæ­¥éª¤å®ç°æŒä¹…åŒ–
> - **å‘½ä»¤è¿½åŠ **: æ¯ä¸ªå†™å‘½ä»¤éƒ½ä¼šä»¥åè®®æ ¼å¼è¿½åŠ åˆ°aof_bufç¼“å†²åŒºã€‚
>
> - **æ–‡ä»¶å†™å…¥åŒæ­¥**:RedisæœåŠ¡è¿›ç¨‹å°±æ˜¯ä¸€ä¸ªäº‹ä»¶å¾ªç¯ï¼Œå¤„ç†æ–‡ä»¶äº‹ä»¶ã€æ—¶é—´äº‹ä»¶ç­‰ã€‚åœ¨å†™çš„æ–‡ä»¶äº‹ä»¶å¾ªç¯ç»“æŸå‰ï¼Œéƒ½ä¼šè°ƒç”¨flushAOFå‡½æ•°æ¥å°†aof_bufä¸­çš„æ•°æ®å†™å…¥å’Œä¿å­˜åˆ°`AOF`æ–‡ä»¶ä¸­ã€‚åŒæ—¶æ ¹æ®`appedfsync`é€‰é¡¹å¯¹å†™å…¥å‘½ä»¤è¿›è¡Œå®é™…æ–‡ä»¶åŒæ­¥è½ç›˜æ“ä½œã€‚
>
>> -  appendfsync: ***always(å¯èƒ½ä¸¢å¤±ä¸€ä¸ªäº‹ä»¶å†…çš„çš„æ‰€æœ‰å†™å‘½ä»¤)***ã€everysec(ä¼šä¸¢å¤±ä¸€ç§’é’Ÿæ•°æ®)ã€no(æ–‡ä»¶åŒæ­¥æ“ä½œç”±æ“ä½œç³»ç»Ÿå†³å®šï¼ŒRedisé‡å¯ä¼šä¸¢å¤±æ•°æ®)
>> - AOFæœ‰æ–‡ä»¶é‡å†™åŠŸèƒ½ä»¥å‹ç¼©æ—¥ç›Šè†¨èƒ€çš„aofæ–‡ä»¶ä½“ç§¯
> - AOFä¿å­˜å†™å‘½ä»¤è¿‡ç¨‹ï¼Œæ•°æ®æ¢å¤é€Ÿåº¦è¾ƒæ…¢
2. `RDB(Redis Data Binary)`ä½¿ç”¨é”®å€¼å¯¹çš„å‹ç¼©äºŒè¿›åˆ¶æ–‡ä»¶ä¿å­˜æ•°æ®åº“çŠ¶æ€ã€‚
> - é€šè¿‡SAVEå’ŒBGSAVEä¸¤ç§å‘½ä»¤åˆ›å»ºRDBæ–‡ä»¶ï¼Œå‰è€…åˆ›å»ºæ—¶ä¼šé˜»å¡å·¥ä½œè¿›ç¨‹ï¼Œè€Œåè€…åˆ™å¦èµ·ä¸€ä¸ªå­è¿›ç¨‹åšåˆ›å»ºå·¥ä½œä¸ä¼šé˜»å¡Rediså·¥ä½œè¿›ç¨‹ã€‚
> - Rediså‘¨æœŸæ€§æ“ä½œå‡½æ•°serverCronï¼Œå®šæœŸæ£€æŸ¥æ˜¯å¦æ»¡è¶³RDBæ“ä½œæ¡ä»¶(save 600 3. 600ç§’å†…è‡³å°‘æ“ä½œäº†3æ¬¡ä¿®æ”¹)ã€‚å¦‚æœæ»¡è¶³åˆ™è¿›è¡ŒRDBç›¸å…³æ“ä½œã€‚ç±»ä¼¼å®šæ—¶å™¨æ“ä½œ***æ‰€ä»¥è¾ƒå®¹æ˜“ä¸¢å¤±æ•°æ®***
> - RDBç´§å‡‘çš„å•æ–‡ä»¶ä¿å­˜æ•°æ®å¿«ç…§ï¼Œæ˜“äºä¼ è¾“ä¸”æ•°æ®æ¢å¤é€Ÿåº¦å¿«
>

3. In theory, **for asynchronous replication**, there is no guarantee to prevent data loss. ç†è®ºä¸Šï¼Œå¼‚æ­¥æ•°æ®å¤åˆ¶æ— æ³•ä¿è¯æ•°æ®ä¸ä¸¢å¤±
> -  However, this is an extremely low probability scenario as described above.ä½†æ˜¯å¯ä»¥æå¤§å‡å°‘å‡ºç°çš„æ¦‚ç‡



* ### OOP
>- Difference between a `Reference` variable and a `Pointer` in C++?
>A pointer stores the address of the variable whereas a reference variable is just an alias for that variable.



### Design Pattern
> - **Factory Method Pattern** is defined as providing an interface for object creation but delegating the actual instantiation of objects to subclasses. ä¸ºå¯¹è±¡çš„åˆ›å»ºæä¾›ä¸€ä¸ªæ¥å£ï¼Œä½†å°†å¯¹è±¡å®ä¾‹åŒ–å§”æ‰˜ç»™å­ç±»ã€‚
> - **Abstract factory pattern** is defined as defining an interface to create families of related or dependent objects without specifying their concrete classes. å®šä¹‰ä¸€ä¸ªæ¥å£æ¥åˆ›å»ºç›¸å…³æˆ–ä¾èµ–å¯¹è±¡çš„å®¶æ—ï¼Œè€Œä¸ç”¨æŒ‡å®šå®ƒä»¬çš„å…·ä½“ç±»ã€‚
> - **Observer Pattern** is defined as a one to many dependency between objects so that when one object changes state all the dependents are notified.å®šä¹‰äº†ä¸€å¯¹å¤šçš„ç±»å…³ç³»ã€‚å½“ä¸€ä¸ªsubjectçŠ¶æ€å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ‰€æœ‰observeèƒ½å¤Ÿæ„ŸçŸ¥åˆ°ã€‚
> - **State Pattern** is defined as allowing an object to alter behavior when its internal state changes so that it appears to change its class. å…è®¸å¯¹è±¡åœ¨å…¶å†…éƒ¨çŠ¶æ€å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ”¹å˜å…¶è¡Œä¸ºã€‚çœ‹ä¸Šå»å°±åƒæ”¹å˜äº†è‡ªèº«æ‰€å±ç±»ä¸€æ ·ã€‚
> - **Prototype** is a creational design pattern that lets you copy existing objects without making your code dependent on their classes.æ˜¯ä¸€ç§åˆ›å»ºæ¨¡å¼ã€‚å…è®¸åœ¨ä¸ä¾èµ–å…¶ä»–ç±»çš„å‰æä¸‹å¤åˆ¶æ­¤ç±»å¯¹è±¡ã€‚



### TCP Finite State Machine

>- ![](http://www.tcpipguide.com/free/diagrams/tcpfsm.png)
>- <img src="https://coolshell.cn/wp-content/uploads/2014/05/tcp_open_close.jpg" style="zoom:60%;" />
>- ä»TIME_WAITçŠ¶æ€åˆ°CLOSEDçŠ¶æ€ï¼Œæœ‰ä¸€ä¸ªè¶…æ—¶è®¾ç½®æ˜¯ 2*MSLï¼ˆ[RFC793](https://tools.ietf.org/html/rfc793)ï¼‰ä¸ºä»€ä¹ˆè¦è¿™æœ‰TIME_WAITï¼Ÿä¸ºä»€ä¹ˆä¸ç›´æ¥ç»™è½¬æˆCLOSEDçŠ¶æ€å‘¢ï¼Ÿä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š
>>- 1ï¼‰TIME_WAITç¡®ä¿æœ‰è¶³å¤Ÿçš„æ—¶é—´è®©å¯¹ç«¯æ”¶åˆ°ACKï¼Œèƒ½å¤Ÿå®‰å…¨æ­£ç¡®çš„å…³é—­åŒå…¨å·¥TCPè¿æ¥ã€‚å¦‚æœè¢«åŠ¨å…³é—­çš„é‚£æ–¹æ²¡æœ‰æ”¶åˆ°ACKå°±ä¼šè§¦å‘è¢«åŠ¨ç«¯é‡å‘FINï¼Œä¸€æ¥ä¸€å»æ­£å¥½2ä¸ªMSLã€‚
>>- 2ï¼‰é˜²æ­¢æ—§é“¾æ¥çš„**è¿·èµ°segment**(e.g. **è¿·èµ°**å°±æ˜¯ç”±äºè·¯ç”±åè®®çš„é—®é¢˜ï¼ŒTCPåˆ†ç»„è¢«è·¯ç”±å™¨Aè½¬å‘ç»™è·¯ç”±å™¨Bï¼Œéšååˆè¢«è·¯ç”±å™¨Bè½¬å‘ç»™è·¯ç”±å™¨A)ï¼Œå½±å“æ–°è¿æ¥(æ–°æ—§é“¾æ¥ç›¸åŒå››å…ƒç»„)ã€‚
>- å¦‚æœä¸¤è¾¹åŒæ—¶æ–­è¿æ¥ï¼Œé‚£ä¸¤è¾¹å°±éƒ½ä¼šå°±è¿›å…¥åˆ°CLOSINGçŠ¶æ€ï¼Œç„¶ååˆ°è¾¾TIME_WAITçŠ¶æ€ã€‚ä¸‹å›¾æ˜¯åŒæ–¹åŒæ—¶æ–­è¿æ¥çš„ç¤ºæ„å›¾ã€‚
><img src="http://www.tcpipguide.com/free/diagrams/tcpclosesimul.png" style="zoom:100%"/>
------
### HTTPS
How does HTTPS work?

Hypertext Transfer Protocol Secure (HTTPS) is an extension of the Hypertext Transfer Protocol (HTTP.) HTTPS transmits encrypted data using Transport Layer Security (TLS.) If the data is hijacked online, all the hijacker gets is binary code.<img src="D:\EastMoney\LeetCode\pictures\https.jpg" style="zoom:47%;" />

> Step 1 - The client (browser) and the server **establish a TCP connection**.åˆ›å»ºTCPè¿æ¥
>
> Step 2 - The client sends a â€œ**client hello**â€ to the server. The message contains a set of necessary encryption algorithms and the latest TLS version it can support. The server responds with a â€œ**server hello**â€ so the browser knows whether it can support the algorithms and TLS version.The **server then sends the SSL certificate to the client**. The certificate contains the public key, host name, expiry dates, etc. The client validates the certificate.å®¢æˆ·ç«¯ä¸æœåŠ¡æ®µç›¸äº’å‘é€helloï¼Œç”¨ä»¥ç¡®å®šåŠ å¯†ç®—æ³•å’ŒTLSç‰ˆæœ¬ã€‚ç¡®å®šå¥½åæœåŠ¡æ®µå‘é€è¯ä¹¦ç»™å®¢æˆ·ç«¯ï¼Œè¯ä¹¦ä¸­åŒ…å«å…¬é’¥ã€è¿‡æœŸæ—¶é—´å’ŒåŸŸåã€‚
>
> Step 3 - After validating the SSL certificate, the **client generates a session key** and encrypts it using the public key. The server receives the encrypted session key and decrypts it with the private key.å®¢æˆ·ç«¯æ ¡éªŒå®Œè¯ä¹¦æ­£ç¡®åç”Ÿæˆsession keyï¼Œå¹¶ç”¨è¯ä¹¦åŠ å¯†åå‘ç»™æœåŠ¡ç«¯ï¼ŒæœåŠ¡ç«¯ç”¨ç§é’¥è§£å¯†å¾—åˆ°session keyã€‚
>
> Step 4 - Now that both the client and the server hold the same session key (**symmetric encryption**), the encrypted data is transmitted in a secure bi-directional channel.å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯é€šè¿‡session keyå¯¹æ•°æ®è¿›è¡Œå¯¹ç§°åŠ å¯†ã€‚
>
> Why does HTTPS switch to symmetric encryption during data transmission? There are two main reasons:
>>1. Security: The asymmetric encryption goes only one way. This means that if the server tries to send the encrypted data back to the client, anyone can decrypt the data using the public key.
>>2. Server resources: The asymmetric encryption adds quite a lot of mathematical overhead. It is not suitable for data transmissions in long sessions.

### MySQL


#### InnoDB Cluster

>- MySQL InnoDB Cluster provides a complete high availability solution for MySQL. Each MySQL server instance in an InnoDB Cluster runs MySQL Group Replication, which provides the mechanism to replicate data within an InnoDB Cluster, with built-in failover.
>- [MySQL Router](https://dev.mysql.com/doc/mysql-router/8.0/en/) can automatically configure itself based on the cluster you deploy, connecting client applications transparently to the server instances.
>- In the default Single-Primary mode, an InnoDB Cluster has a single Read-Write server instance - the Primary. Multiple secondary server instances are replicas of the primary. If the primary fails, a secondary is automatically promoted to the role of primary. 
>- follow diagram show an overview of how the technologies work together:![](https://dev.mysql.com/doc/mysql-shell/8.0/en/images/innodb_cluster_overview.png)

#### InnoDB ä¸»ä»å¤åˆ¶åŸç†
>- MySQL Master å°†æ•°æ®å˜æ›´å†™å…¥äºŒè¿›åˆ¶æ—¥å¿—( binary log, å…¶ä¸­è®°å½•å«åšäºŒè¿›åˆ¶æ—¥å¿—äº‹ä»¶binary log eventsï¼Œå¯ä»¥é€šè¿‡ show binlog events è¿›è¡ŒæŸ¥çœ‹)
>- MySQL Slave å‘Masterå‘é€dumpåè®®ï¼ŒMasteræ”¶åˆ°dumpè¯·æ±‚åå‘Slaveæ¨é€bin logã€‚
>- MySQL Slave å°†binary log events æ‹·è´åˆ°å®ƒçš„ä¸­ç»§æ—¥å¿—(Relay log)ã€‚
>- MySQL Slave é‡æ”¾ relay log ä¸­äº‹ä»¶ï¼Œå°†æ•°æ®å˜æ›´åæ˜ å®ƒè‡ªå·±çš„æ•°æ®ã€‚





### Distributed System


#### CAP
>- **Consistency ( C ):** All users see the same data at the same time.
>- **Availability ( A ):** System continues to function even with node failures.
>- **Partition tolerance ( P ):** System continues to function even if the communication fails between nodes.
#### Data Partitioning
The act of distributing data across a set of nodes is called data partitioning. 
>- **Consistent Hash**: is a special kind of hashing such that when a hash table is re-sized and consistent hashing is used, only $k/n$ keys need to be remapped on average, where $k$ is the number of keys, and $n$ is the number of slots(Each **slot** is represented by **a server** in a distributed system or cluster).ä¸€è‡´å“ˆå¸Œæ˜¯ä¸€ä¸ªhashç¯ï¼Œkeyæ˜ å°„åˆ°ç¯çš„æŸä¸ªä½ç½®åï¼Œç”±æŒ‡å®šçš„node(ä¹Ÿå°±æ˜¯æœåŠ¡å™¨)è´Ÿè´£ã€‚å½“nodeå¢åŠ æˆ–åˆ é™¤å
>> - only a small set of keys move when servers are added or removed.
>> - *This scheme can result in non-uniform data and load distribution*.First, it is impossible to keep the same size of partitions on the ring for all servers considering a server can be added or removed.Second, it is possible to have a non-uniform key distribution on the ring. However solves these issues with the help of ***Virtual Nodes***.

#### Rate limiter
**Rate limiter is used to control the rate of traffic sent by a client or a service**. Include *Token bucket*,*Leaking bucket*,*Fixed window counter*,*Sliding window log*, *Sliding window counter*.

>- Sliding Windows with Redis backend. (ä½¿ç”¨Sorted Seté…åˆzaddï¼Œzremrankbyscoreï¼Œzcard)å®ç°å…¨å±€é™æµå™¨ã€‚Local rate limiting can be used in conjunction with global rate limiting to reduce load on the global rate limit service. Thus, the rate limit is applied in two stages. The initial coarse grained limiting is performed by the token bucket limit before a fine grained global limit finishes the job.å¯ä»¥é…åˆæœ¬åœ°é™æµå™¨å¸æ”¶ç»å¤§éƒ¨åˆ†æµé‡ä»¥ä¿æŠ¤å…¨å±€é™æµå™¨ã€‚æ‰€ä»¥é™æµå™¨å¯ä»¥ç”¨ä¸¤æ­¥å®ç°ã€‚åœ¨ç»†é¢—ç²’åº¦çš„å…¨å±€é™æµå™¨å®Œæˆå·¥ä½œä¹‹å‰ï¼Œåˆå§‹çš„ç²—é¢—ç²’åº¦çš„é™åˆ¶ç”±ä»¤ç‰Œæ¡¶æ‰§è¡Œã€‚

#### RPC
**RPC** (Remote Procedure Call) is called â€œğ«ğğ¦ğ¨ğ­ğâ€ because it enables communications between remote services when services are deployed to different servers. From the userâ€™s point of view, it acts like a local function call.è®©è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„ä¸åŒæœåŠ¡é—´è¿›è¡Œé€šè®¯ï¼Œä»ç”¨æˆ·è§’åº¦çœ‹å°±åƒè°ƒç”¨æœ¬åœ°å‡½æ•°ä¸€æ ·ã€‚

  <img src="D:\EastMoney\LeetCode\pictures\Fg-cdXRVEAArIQf.jpg" style="zoom:43%;" />
#### Distribute Lock
> - **Redis Single Instance Lock**
> >   Set-if-Not-Exists to obtain a lock, atomic Delete-if-Value-Matches to release a lock. **As an efficiency optimization, not for correctness**.For example, a good use case is maintaining request counters per IP address (for rate limiting purposes) and sets of distinct IP addresses per user ID (for abuse detection).ä¸Šé”æ—¶ å¦‚æœæ²¡æœ‰å°±è®¾ç½®key_nameï¼Œå…¶å€¼ä¸ºæ¯ä¸ªç”¨æˆ·ç‰¹å®šéšæœºå€¼uidå¹¶è®¾ç½®è¶…æ—¶ã€‚æ”¾çæ—¶ç”¨æˆ·èƒ½åŒ¹é…uidå°±å¯ä»¥å®‰å…¨åˆ é™¤ï¼Œé˜²æ­¢ç”¨æˆ·é‡Šæ”¾äº†ä»–äººé”ã€‚
> >
> >   ```lua
> >   --acquire the lock
> >   SET key_name client_random_value NX PX 3000
> >   --release the lock
> >   if redis.call("get",KEYS[1]) == ARGV[1] then
> >       return redis.call("del",KEYS[1])
> >   else
> >       return 0
> >   end
> >   ```
> - **Redis Redlock Algorithm**
> > 1. It gets the current time in milliseconds. å®¢æˆ·ç«¯è·å–å½“å‰æ—¶é—´æˆ³ã€‚
> > 2. It tries to acquire the lock in all the $N$ instances **Sequentially**, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.
> >   å®¢æˆ·ç«¯ ä½¿ç”¨ç›¸åŒkeyå’Œéšæœºvalueï¼Œåœ¨Nä¸ªå®ä¾‹ä¸­***é¡ºåº***è·å–é”ã€‚å¦‚æœé”æœ‰æ•ˆæ—¶é—´ä¸º10ç§’ï¼Œåˆ™ä»¤è·å–é”çš„è¶…æ—¶æ—¶é—´ä¸º50æ¯«ç§’ï¼Œä»¥ä¿è¯åœ¨æŸä¸ªå®ä¾‹èŠ‚ç‚¹ä¸å¯è¾¾æ—¶å®¢æˆ·ç«¯èƒ½å°½å¿«çš„è½®è¯¢ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å®ä¾‹ã€‚
> > 3. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired. 
> >   å®¢æˆ·ç«¯é€šè¿‡å…¬å¼è®¡ç®—åŠ é”çš„æ¶ˆè€—æ—¶é—´ $ Tå½“å‰æ—¶é—´æˆ³ - æ­¥éª¤1çš„æ—¶é—´æˆ³$ã€‚å½“ä¸”ä»…å½“å®¢æˆ·ç«¯è·å¾—äº†å¤§éƒ¨åˆ†é”($N/2+1$)ä¸”$T$å°äºé”æœ‰æ•ˆæ—¶é—´ï¼Œåˆ™è®¤ä¸ºå®¢æˆ·ç«¯åŠ é”æˆåŠŸã€‚
> > 4. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3. 
> >   å¦‚æœåŠ é”æˆåŠŸï¼Œåˆ™æ­¤é”çš„æœ‰æ•ˆæ—¶é—´ä¸ºåŸå§‹é”æœ‰æ•ˆæ—¶é—´(10ç§’)å‡å»æ­¥éª¤3ä¸­çš„åŠ é”è€—æ—¶$T$ã€‚
> > 5. If the client failed to acquire the lock for some reason (either it was not able to lock N/2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).
> >   å¦‚æœåŠ é”å¤±è´¥ï¼Œåˆ™ä¼šä¸»åŠ¨é‡Šæ”¾æ‰€æœ‰èŠ‚ç‚¹é”ã€‚
> - **Zookeeper** is a distributed key-value store and is used for coordination and storing configurations. It is highly optimized for reads. åŸºäºredisçš„åˆ†å¸ƒå¼é”æœ‰ä¸¤ä¸ªé—®é¢˜
> - æœ‰fencing tockené”™è¯¯ï¼Œå¦‚ä¸‹å›¾
> <img src="D:\EastMoney\LeetCode\pictures\fencingtoken.JPG" alt="10%" style="zoom: 86%;" />
> 
>- åŸºäºåˆ†å¸ƒå¼ç³»ç»Ÿæ—¶é—´å‡è®¾æƒ…å†µã€‚å³åˆ†å¸ƒå¼ç³»ç»Ÿä¸­æ¯ä¸ªèŠ‚ç‚¹çš„æœ¬åœ°æ—¶é—´åŸºæœ¬ä¸€è‡´å¢å¼ æ–¹å‘ç›¸åŒï¼Œä¸”é”æœ‰æ•ˆæœŸè¿œå¤§äºèŠ‚ç‚¹é—´çš„æ—¶é—´æ¼‚ç§»ã€‚(NTPä¸æœ¬åœ°æ—¶é—´å·®è·å·¨å¤§ï¼Œç®¡ç†å‘˜ä¿®æ”¹äº†æ—¶é—´ç­‰æƒ…å†µ)ã€‚
> 
>> 1.åˆ›å»ºæ°¸ä¹…å±æ€§znodeä½œä¸ºé”èŠ‚ç‚¹ã€‚
> > 2.ç”¨æˆ·åŠ é”æ—¶åœ¨é”èŠ‚ç‚¹ä¸‹åˆ›å»ºä¸´æ—¶æœ‰åºznodeã€‚
> > 3.ç”¨æˆ·åŠ é”æ—¶å¦‚ä¸‹ï¼š
> > 3-1. åœ¨é”èŠ‚ç‚¹ä¸‹åˆ›å»ºä¸´æ—¶æœ‰åºå­èŠ‚ç‚¹ã€‚EPHEMERAL_SEQUENTIAL znode
>> 3-2. æŸ¥æ‰¾é”èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹å¹¶æŒ‰åºå·æ’åºã€‚
>> 3-3. å¦‚æœåºå·æ˜¯æœ€å°åºå·å­èŠ‚ç‚¹åˆ™åŠ é”æˆåŠŸã€‚
>> 3-4. å¦‚æœä¸æ˜¯æœ€å°åºå·åˆ™ç›‘å¬ä¸Šä¸€ä¸ªå­èŠ‚ç‚¹çš„å˜åŠ¨ï¼Œå¹¶ç­‰å¾…ã€‚é˜²æ­¢æƒŠç¾¤ç°è±¡ã€‚
>> 4.ç”¨æˆ·é‡Šæ”¾çæ—¶ï¼Œç›´æ¥åˆ é™¤å…¶åˆ›å»ºçš„ä¸´æ—¶æœ‰åºå­èŠ‚ç‚¹ã€‚

####Kafka

Kafka was created at LinkedIn around 2010 to track various events, such as page views, messages from the messaging system, and logs from various services.
A Kafka server is also called a **broker**. Brokers are responsible for reliably storing data provided by the producers and making it available to the consumers.Kafka divides its messages into categories called **Topics**. In simple terms, a **topic** is like a table in a database, and the messages are the rows in that table.As topics can get quite big, they are split into **partitions** of a smaller size for better performance and scalability.Kafka guarantees that **all messages inside a partition are stored in the sequence they came in**. **Ordering** of messages is maintained **at the partition level**, not across the topic.By using **consumer groups**, consumers can be parallelized so that multiple consumers can read from multiple partitions on a topic, allowing a very high message processing throughput. 

A **leader** **is the node responsible for *all* reads and writes** for the given partition. **Every partition** has one Kafka broker **acting as a leader**.To handle single point of failure, Kafka can replicate partitions and distribute them across multiple broker servers called **followers**.

**To handle split-brain** (where we have **multiple active controller brokers**), Kafka uses â€˜epoch number,â€™ which is simply a monotonically increasing number to indicate a serverâ€™s generation.**This epoch is included in every request that is sent from the Controller to other brokers**.This way, brokers can easily differentiate the real Controller by simply **trusting the Controller with the highest number**. This epoch number is stored in ZooKeeper.

- How can a producer know that the data is successfully stored at the leader or that the followers are keeping up with the leaderï¼Ÿç”Ÿäº§è€…ä¿è¯æ•°æ®å†™å…¥æˆåŠŸçš„å‡ ç§æ–¹å¼
> **Async**: Producer sends a message to Kafka and does not wait for acknowledgment from the server. 
> **Committed to Leader**: Producer waits for an acknowledgment from the leader. 
> **Committed to Leader and Quorum**: Producer waits for an acknowledgment from the leader and the quorum.
- What message-delivery guarantees does Kafka provide to consumers? kafkaæ€æ ·ä¿è¯æ¶ˆè´¹è€…æ¶ˆè´¹åˆ°æ•°æ®ã€‚
> **At-most-once**: Messages may be lost but are never redelivered.**Consumers** commit message offsets before they process them.æ¶ˆè´¹è€…å…ˆcommit offsetå†å¤„ç†æ¶ˆæ¯ã€‚
> **At-least-once**: Messages are never lost but may be redelivered.**Consumer** can process the message first and then commit the offset. æ¶ˆè´¹è€…å…ˆå¤„ç†æ¶ˆæ¯å†commit offsetã€‚
> **Exactly-once**: Each message is delivered once and only once. Tags every message with a sequence number. In this way, the broker can keep track of the largest number per PID and reject duplicates.
------
Why is Kafka fast?
<img src="D:\EastMoney\LeetCode\pictures\kafaka-zerocopy.jpg" style="zoom: 63%;" />

#### Quorum Consensus æ³•äººå…±è¯†ç®—æ³•
**Quorum consensus** can guarantee consistency for both read and write operations.The configuration of $W$, $R$ and $N$ is a typical tradeoff between latency and consistency.

>- $N$ = The number of replicas.
>- $W$ = A write quorum of size $W$. For a write operation to be considered as successful, write
operation must be acknowledged from $W$ replicas.
>- $R$ = A read quorum of size $R$. For a read operation to be considered as successful, read
operation must wait for responses from at least $R$ replicas.

####Bloom Filter
**Bloom Filter** how to make a valid choice of parameter.[here](https://hur.st/bloomfilter/)
>- $n$  number of items in the filter.
>- $m$ number of bits in the filter.
>- $k$  number of hash functions.
>- $p$ probability of **False Positives**. fraction between 0 and 1 or a number indicating $1$-in-$p$.